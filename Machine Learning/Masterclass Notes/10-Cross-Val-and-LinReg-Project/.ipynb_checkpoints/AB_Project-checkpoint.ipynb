{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Train | Test Split Procedure \n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Test Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Test Data (by creating predictions and comparing to Y_test)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into X & y, removing the sales data to create X..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...And using the sales data as y -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the train_test_split function from SciKit-Learn -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy this from the 'train_test_split' help text, hit 'Shift+Tab' to access the text, and scroll down -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a scaling function to apply to the data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember in order to prevent data leakage, ***we only fit to the training data -***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scaler to the training data sets -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data scaled, we will now create the model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Remember 'alpha' is basically the weight we will apply to the model, how well we want it to apply itself to the training data...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the data on to the model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this fit we will have our predictions, so here we are saying 'Predict on the X_test' -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import out metric to assess our results -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mean_squared_error to the test and prediction values to determine the predicted values to the actual -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.341775789034129"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to evaluate the model, we will create a second model to adjust the hyperparameter 'alpha' of to compare results -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data now to this new model so we can compare the results -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_two.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another prediction -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again run the mean_squared_error function to compare that figure with the initial mse figure with alpha=100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Notice the better performance (lower deviation of the predictions from the actual test data = lower mse) with the updated alpha value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whilst Training and Testing works fine in most applications, below we will split further into a validation set enabling us to test models on purely unseen data.\n",
    "The 3 sets are:\n",
    "- **Training** - to create and fit the model to,\n",
    "- **Test** - to verify and gauge the performance of the model on, with the ability to return to the training set to adjust figures as required, &\n",
    "- **Validation** - as a purely unseen data set used for FINAL validation of the model's performance. Once the Validation set has been passed in, there should be **NO** alteration to the model.\n",
    "\n",
    "Using a Validation set, we know that the modeal was not fit to this data, **AND** the model's hyperparameters were not adjusted off that data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Train | Test | Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often called a \"hold-out\" set, since we should not adjust parameters based on the final test set, instead use it *only* for reporting final expected performance.\n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Validation/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Eval Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Evaluation Data (by creating predictions and comparing to Y_eval)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6\n",
    "8. Get final metrics on Test set (not allowed to go back and adjust after this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will recreate our X & y sets -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import the train_test_split model, and perform the method ***TWICE*** to first seperate the train and test sets, and *then* to split the test set into **test** and **evaluation** sets (named accordingly) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% of the data is training data, the other 30% is set aside for validation (hence is named 'OTHER')\n",
    "X_train, X_OTHER, y_train, y_OTHER = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# The remaining 30% is split into evaluation and test sets\n",
    "# Each is 15% of the original data size\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_OTHER, y_OTHER, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the lengths of each, notice that the lengths of **X_train**, **X_eval** & **X_test** all sum to the length of the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to import and apply scaling to the data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we **fit** to ONLY the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scaler to the X sets -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = scaler.transform(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import and create our *first* instance of the model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...with alpha value 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the training data to fit the model -\n",
    "- X_train: The contributing factors\n",
    "- y_train: The associated outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass in the X_eval dataset to the created model to gauge performance -\n",
    "- X_eval: is like the original 'test' set, and is a data set of the factors used to generate an estimated output by passing it to the 'predict' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model_one.predict(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate, import the mean_squared_error function -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the 'y_eval' (actual evaluation figures) and the predicted 'y_eval_pred' to compare via the mean_squared_error -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.320101458823872"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the above figure is *close* but not the same as the previously predicted mean_squared_error figure, because we are testing off of *half* the data allocated for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the second model, with alpha figure 1 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, fit that model to the X_train & y_train sets, but with a different alpha figure -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_two.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, pass the 'X_eval' to the new model to gauge performance -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = model_two.predict(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then apply the mean_squared_error to compare the two -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3837830750569866"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_eval,new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the previous two fits and mse calcs have been performed with a small knowledge of the test set, now we will bring the test set into play and compare -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_predictions = model_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.254260083800517"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test,y_final_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **K-Fold** Cross Validation, starting with a complete dataset, we will split it into a larger training & smaller test portions.\n",
    "\n",
    "The **test** set will be removed to be used for final model evaluation, thus it cannot be used to train the model for fear that it could bias the fitting of the model.\n",
    "\n",
    "For the **training** data, we will identify what is known as the *K-Value*, which is the number of divisions we will split the data into in order to perform our cross validation functions. Remembering though that whilst the largest K-Value possible (number of rows - 1) may seem ideal, it will lead to increased calculations and processor use.\n",
    "\n",
    "Cross validation is a practice of training a model whilst leaving a certain portion of that model aside for validation. Iterating through the dataset, the portion of data used for validation will change with every iteration and the error noted. This allows us to train AND validate our model on ALL portions of the data.\n",
    "\n",
    "After iterating through all the data, the collection of errors are then averaged to identify possible hyperparameter adjustments, before the cross-validation function is then run again.\n",
    "\n",
    "Following cross validation, we then test the model on our segregated test dataset as normal.\n",
    "\n",
    "\n",
    "<img src=\"grid_search_cross_validation.png\">\n",
    "\n",
    "----\n",
    "\n",
    "#### SciKit Learn's *'cross_val_score'* function allows us to perform this function automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will perform our train test split as per normal to remove our test data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When removing the final test data, with cross validation our test size doesn't need to be *too* large (can be 15, 20% for example). We will leave it at 30% for this example to keep our results comparable to the previous model outcomes -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the 'cross_val_score' function, we must pass in:\n",
    "\n",
    "- The instance of the model we are using (in this case it's 'model')\n",
    "- Our training datasets X & y, &\n",
    "- Our scoring function\n",
    "- The K-fold value as 'cv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train,y_train,scoring=\"neg_mean_squared_error\",cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see our scores -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "        -8.38562723])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remembering that as we're looking at the negative mse, the higher number (that is the *lowest* negative integer value) here is the better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from theses scores we can now generate the average (as an absolute value), and compare that to our values from our previous models -\n",
    "\n",
    "Seen here, this not such a good value compared to other methods performed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.215396464543607"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the same functions, but adjusting our alpha values to gauge performance and improvements -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model_a,X_train,y_train,scoring=\"neg_mean_squared_error\",cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen below, a much better score than the original, but still with room for improvement -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.344839296530695"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred = model_a.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we have our final mean_sqaured_error from the cross validation model fit -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Cross Validation with the cross_validate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross_validate** allows us to view numerous performance metrics on a model and provides feedback on times taken to both fit and test models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# Our set used for cross validation -\n",
    "X_train = scaler.transform(X_train)\n",
    "# Our set used for final performance metrics -\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the **cross_validate** function -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross_validate we can pass in a list of methods to score off of, which will return a dictionary of scores -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model,X_train,y_train,scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00199246, 0.00199413, 0.00099802, 0.00199533, 0.00099826,\n",
       "        0.00099754, 0.00099707, 0.00099778, 0.00099707, 0.00099778]),\n",
       " 'score_time': array([0.00199389, 0.0009973 , 0.00099611, 0.00099874, 0.00099683,\n",
       "        0.        , 0.00099754, 0.0009973 , 0.00099754, 0.0019927 ]),\n",
       " 'test_neg_mean_absolute_error': array([-1.8102116 , -2.54195751, -1.46959386, -1.86276886, -2.52069737,\n",
       "        -2.45999491, -1.45197069, -2.37739501, -2.44334397, -1.89979708]),\n",
       " 'test_neg_mean_squared_error': array([ -6.06067062, -10.62703078,  -3.99342608,  -5.00949402,\n",
       "         -9.14179955, -13.08625636,  -3.83940454,  -9.05878567,\n",
       "         -9.05545685,  -5.77888211]),\n",
       " 'test_max_error': array([ -5.89305462,  -6.06524931,  -5.26424161,  -4.29881153,\n",
       "         -5.61586024, -10.60207363,  -4.73613382,  -6.520936  ,\n",
       "         -7.37049532,  -5.41946249])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this convoluted data into a Pandas DataFrame to make it more readable -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-1.810212</td>\n",
       "      <td>-6.060671</td>\n",
       "      <td>-5.893055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-2.541958</td>\n",
       "      <td>-10.627031</td>\n",
       "      <td>-6.065249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>-1.469594</td>\n",
       "      <td>-3.993426</td>\n",
       "      <td>-5.264242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>-1.862769</td>\n",
       "      <td>-5.009494</td>\n",
       "      <td>-4.298812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-2.520697</td>\n",
       "      <td>-9.141800</td>\n",
       "      <td>-5.615860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.459995</td>\n",
       "      <td>-13.086256</td>\n",
       "      <td>-10.602074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-1.451971</td>\n",
       "      <td>-3.839405</td>\n",
       "      <td>-4.736134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-2.377395</td>\n",
       "      <td>-9.058786</td>\n",
       "      <td>-6.520936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-2.443344</td>\n",
       "      <td>-9.055457</td>\n",
       "      <td>-7.370495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-1.899797</td>\n",
       "      <td>-5.778882</td>\n",
       "      <td>-5.419462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.001992    0.001994                     -1.810212   \n",
       "1  0.001994    0.000997                     -2.541958   \n",
       "2  0.000998    0.000996                     -1.469594   \n",
       "3  0.001995    0.000999                     -1.862769   \n",
       "4  0.000998    0.000997                     -2.520697   \n",
       "5  0.000998    0.000000                     -2.459995   \n",
       "6  0.000997    0.000998                     -1.451971   \n",
       "7  0.000998    0.000997                     -2.377395   \n",
       "8  0.000997    0.000998                     -2.443344   \n",
       "9  0.000998    0.001993                     -1.899797   \n",
       "\n",
       "   test_neg_mean_squared_error  test_max_error  \n",
       "0                    -6.060671       -5.893055  \n",
       "1                   -10.627031       -6.065249  \n",
       "2                    -3.993426       -5.264242  \n",
       "3                    -5.009494       -4.298812  \n",
       "4                    -9.141800       -5.615860  \n",
       "5                   -13.086256      -10.602074  \n",
       "6                    -3.839405       -4.736134  \n",
       "7                    -9.058786       -6.520936  \n",
       "8                    -9.055457       -7.370495  \n",
       "9                    -5.778882       -5.419462  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then take the mean values to see the averages...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                        0.001297\n",
       "score_time                      0.001097\n",
       "test_neg_mean_absolute_error   -2.083773\n",
       "test_neg_mean_squared_error    -7.565121\n",
       "test_max_error                 -6.178632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it with our better alpha score, then run the same code again -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model,X_train,y_train,scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-1.457174</td>\n",
       "      <td>-2.962508</td>\n",
       "      <td>-2.680446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.555308</td>\n",
       "      <td>-3.057378</td>\n",
       "      <td>-3.251285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-1.238770</td>\n",
       "      <td>-2.173740</td>\n",
       "      <td>-2.708825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>-0.768938</td>\n",
       "      <td>-0.833034</td>\n",
       "      <td>-1.495801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-1.434489</td>\n",
       "      <td>-3.464018</td>\n",
       "      <td>-4.427072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.494316</td>\n",
       "      <td>-8.232647</td>\n",
       "      <td>-9.637507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-1.081362</td>\n",
       "      <td>-1.905864</td>\n",
       "      <td>-3.006887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>-1.250011</td>\n",
       "      <td>-2.765048</td>\n",
       "      <td>-4.279490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.580971</td>\n",
       "      <td>-4.989505</td>\n",
       "      <td>-6.052545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>-1.223326</td>\n",
       "      <td>-2.846438</td>\n",
       "      <td>-3.732716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.000998    0.000997                     -1.457174   \n",
       "1  0.000996    0.000000                     -1.555308   \n",
       "2  0.000000    0.001005                     -1.238770   \n",
       "3  0.000991    0.000959                     -0.768938   \n",
       "4  0.000997    0.000997                     -1.434489   \n",
       "5  0.000998    0.000000                     -1.494316   \n",
       "6  0.000000    0.000998                     -1.081362   \n",
       "7  0.000997    0.001036                     -1.250011   \n",
       "8  0.000997    0.000000                     -1.580971   \n",
       "9  0.000000    0.000994                     -1.223326   \n",
       "\n",
       "   test_neg_mean_squared_error  test_max_error  \n",
       "0                    -2.962508       -2.680446  \n",
       "1                    -3.057378       -3.251285  \n",
       "2                    -2.173740       -2.708825  \n",
       "3                    -0.833034       -1.495801  \n",
       "4                    -3.464018       -4.427072  \n",
       "5                    -8.232647       -9.637507  \n",
       "6                    -1.905864       -3.006887  \n",
       "7                    -2.765048       -4.279490  \n",
       "8                    -4.989505       -6.052545  \n",
       "9                    -2.846438       -3.732716  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see our better performing scores -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                        0.000697\n",
       "score_time                      0.000699\n",
       "test_neg_mean_absolute_error   -1.308467\n",
       "test_neg_mean_squared_error    -3.323018\n",
       "test_max_error                 -4.127257\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we're happy with our results, we can now fit this model to all of our data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again, let's run a mean_squared_error comparison of the actual outputs against our predicted to gauge performance -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test,y_final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
